# D3D12 Backend Code Quality Audit

Scope: `src/igl/d3d12` and D3D12-facing test harness as of this run. Line numbers are taken from the current tree; they may drift in future edits.

## Findings Table

| ID | Category | File:line | Evidence | Rationale / Impact |
|----|----------|-----------|----------|--------------------|
| Q1 | RootSig / Descriptors | `src/igl/d3d12/Device.cpp:969-972`, `src/igl/d3d12/D3D12PipelineCache.h:183-190`, `src/igl/d3d12/D3D12PipelineBuilder.cpp:574-599` | Compute and graphics pipelines construct descriptor ranges with `NumDescriptors = UINT_MAX` for Tier‑2/3 (`const UINT uavBound = needsBoundedRanges ? 64 : UINT_MAX;` etc.), but both `D3D12PipelineCache::getOrCreateRootSignature` and `D3D12RootSignatureBuilder::buildRootSignature` always serialize `D3D12_ROOT_SIGNATURE_DESC` with `D3D_ROOT_SIGNATURE_VERSION_1`. | Unbounded descriptor ranges are a Root Signature 1.1 feature and are formally described for `D3D12_VERSIONED_ROOT_SIGNATURE_DESC` and `D3D12_DESCRIPTOR_RANGE1`. Using `UINT_MAX` with a v1.0 root signature can produce validation warnings or failures, especially on hardware where `D3D12_FEATURE_DATA_ROOT_SIGNATURE::HighestVersion` is `D3D_ROOT_SIGNATURE_VERSION_1_0`. This also ignores device‑reported `highestRootSignatureVersion_` and risks non‑portable behavior across binding tiers. |
| Q2 | Caps wiring | `src/igl/d3d12/D3D12Context.cpp:560-572`, `src/igl/d3d12/D3D12PipelineCache.h:183-190` | `D3D12Context::createDevice` correctly queries `D3D12_FEATURE_ROOT_SIGNATURE` and stores `highestRootSignatureVersion_`, but this field is never consulted when serializing root signatures; all call sites hard‑code `D3D_ROOT_SIGNATURE_VERSION_1`. | The backend is partially feature‑aware (it logs the highest RS version) but does not actually vary serialization or descriptor range patterns based on it. On GPUs that only expose v1.0, this means unbounded ranges are still used instead of falling back to bounded ranges; on v1.1 devices, the code never takes advantage of `D3D12_ROOT_SIGNATURE_VERSION_1_1` capabilities (descriptor flags, more expressive tables). This is a conformance/robustness gap rather than a crash bug, but it directly touches root signature correctness. |
| Q3 | Sync / Performance | `src/igl/d3d12/Buffer.cpp:180-260,488`, `src/igl/d3d12/CommandQueue.cpp:40-68` | `Buffer::upload` allocates a transient command list, performs barriers, executes it, signals a per‑upload fence, and then calls `device_->waitForUploadFence(uploadFenceValue)` before returning. `CommandQueue::executeDeferredCopies` (called from `submit`) also calls `ctx.waitForGPU()` before iterating deferred `copyTextureToBuffer` operations. | Both paths introduce full GPU waits in hot upload/copy flows, effectively serializing CPU and GPU for each upload or deferred readback. While this is not a functional error, it contradicts D3D12’s recommended pattern of asynchronous uploads with fences polled at frame boundaries. On high‑latency GPUs this can severely reduce throughput and is at odds with the frame‑ring fence model already present elsewhere in the backend. |
| Q4 | Test harness / debug layer wiring | `src/igl/tests/util/device/d3d12/TestDevice.cpp:14-24`, `src/igl/d3d12/D3D12Context.cpp:390-418`, `artifacts/unit_tests/D3D12/IGLTests_Debug.log:2982-2985`, `artifacts/unit_tests/D3D12/IGLTests_Release.log:last` | The test device factory logs `[Tests] D3D12 test device requested (debug layer: disabled)` and ignores its `enableDebugLayer` parameter; D3D12 debug/GBV/DRED are controlled only through environment variables inside `D3D12Context::createDevice`. The unit‑test logs for this run contain no captured D3D12 InfoQueue messages and repeatedly show “debug layer: disabled” in the test harness banner even though the environment was configured for validation. | There is no explicit, test‑local guarantee that the D3D12 debug layer, GPU‑based validation, and DRED are enabled and that their InfoQueue output is captured into artifacts. Validation behavior is thus implicit and fragile: it depends on environment and build flags rather than the test harness itself. From an audit standpoint, this makes it impossible to assert that all D3D12 validation warnings were observed and stored under `artifacts/validation/*` as required. |
| Q5 | Unit‑test failures (non‑API but relevant) | `artifacts/mandatory/unit_tests.log:1-24`, `artifacts/unit_tests/D3D12/IGLTests_Debug.log:2932`, `artifacts/unit_tests/D3D12/IGLTests_Release.log:2837` | The mandatory harness reports `Unit Tests: FAIL`. Debug run: `[  FAILED  ] TextureLoaderFactoryTest.loadKtx2 (176 ms)`. Release run: `[  FAILED  ] TextureLoaderFactoryTest.loadHdr (211 ms)` with process exit code 3. Both failures occur in the D3D12 configuration (other backends disabled). | These failures are not direct D3D12 API misuse but they represent unresolved regressions in the D3D12 test configuration: the texture loader tests either rely on CPU‑side assumptions that no longer hold (e.g., stricter `TextureRangeDesc::validate` checks) or surface latent bugs in the loader pipeline when exercised through the D3D12 test harness. From a “zero‑regression” standpoint, they must be treated as defects blocking the gate until triaged and either fixed or explicitly excluded with justification. |

No additional D3D12 ResourceBarrier, descriptor heap, or fence misuse was detected in the reviewed files (`Buffer.cpp`, `Texture.cpp`, `RenderCommandEncoder.cpp`, `ComputeCommandEncoder.cpp`, `CommandQueue.cpp`, `D3D12Context.cpp`, `DescriptorHeapManager.cpp`, `UploadRingBuffer.cpp`, `Timer.cpp`, `D3D12FrameManager.cpp`, `D3D12PresentManager.cpp`, `ShaderModule.cpp`) for this snapshot; the remaining issues from earlier audits that targeted DEFAULT‑heap uploads, copyTextureToBuffer stubs, CBV alignment, binding tiers, and tearing gating appear to be addressed in the current code base.

